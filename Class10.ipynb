{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonathan-Nyquist/PLAM/blob/main/Class10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxvgekngVRdG"
      },
      "source": [
        "# Advanced Topics in Python\n",
        "\n",
        "## Learning Objectives:\n",
        "Until now, you been learning the basics of programming in Python -- enough to begin exploring further on your own. In the final few notebooks, I want to give you a taste of the real power of Python programming. **Do not worry if you don't understand everything.** Just follow along in the notebooks to see the possibilities. Some of the tasks will continue to follow our Martian theme, but I'll include some down-to-Earth examples to get you thinking about ways you might use programming in your own career (assuming you don't go to Mars).\n",
        "\n",
        "I think you'll be surprised at how much you actually do understand, and I hope you'll be inspired to investigate further on your own!  But some of this stuff is tricky, so don't rush through the notebooks.\n",
        "\n",
        "**Read everything carefully.**\n",
        "\n",
        "## Three themes will comprise our final week:\n",
        "1. ** Advanced data input: Class 10 **\n",
        "2. ** Advanced data analysis: Class 11 **\n",
        "3. ** Advanced data display: Class 12 **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0MiJkrwVRdI"
      },
      "source": [
        "<a id='Top'> </a>\n",
        "## Class 10: Advanced Data Input\n",
        "[Top of Notebook](#Top)\n",
        "Until now you have either data you typing in directly, read from a text file such as comma-separated variable (CSV) file. The internet is all about data, but before you can analyze it you have to be able to read it.\n",
        "\n",
        "In this class we will look at:\n",
        "- [Loading data from an Excel spread sheet](#Excel)\n",
        "- [Loading data from a Google Spreadsheet.](#Googlesheet)\n",
        "- [Loading a JSON file](#JSON)\n",
        "- [Scraping a web page](#Scraping)\n",
        "\n",
        "And, of course, we'll finish with a:\n",
        "- [Martian Mission](#Mission)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Jonathan-Nyquist/PLAM/raw/main/PopularKids.xls"
      ],
      "metadata": {
        "id": "tG2nWKIEWDRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTG57d3xVRdJ"
      },
      "source": [
        "<a id='Excel'></a>\n",
        "## Loading data from an Excel Spreadsheet\n",
        "[Top of Notebook](#Top)\n",
        "\n",
        "In your Class10 folding I've included the file 'PopularKids.xls'\n",
        "\n",
        "Obtained from: http://mercury.webster.edu/aleshunas/Data%20Sets/Supplemental%20Excel%20Data%20Sets.htm\n",
        "\n",
        "A sample of 478 students in grades 4 - 6 were selected from urban, suburban, and rural school districts with approximately 1/3 of the sample coming from each district. The students were asked whether making good grades, being good at sports, or being popular were what they most liked to achieve at school. They were also asked to rank in order of importance the following factors that would make them popular among their friends: making good grades, being good at sports, being handsome or pretty, and having lots of money. They were also asked their gender, grade level, and other demographic information.\n",
        "\n",
        "**Note: This is just an example. I'm not endorsing the research.**\n",
        "```\n",
        "Attributes with possible values:\n",
        "Gender: boy, girl\n",
        "Grade: 4, 5, 6\n",
        "Age: 7,9, 10, 11, 12, 13\n",
        "Race: Other, White\n",
        "Urban/Rural: Rural, Suburban, Urban\n",
        "School: Brentwood Elementary, Brentwood Middle, Brown Middle, Elm, Main, Portage, Ridge, Sand, Westdale Middle\n",
        "Goals: Grades, Popular, Sports (Goals students chose that they most wished to achieve at school)\n",
        "\n",
        "Factors students ranked in order of importance that would make them popular among their friends.\n",
        "(1 = most important, 4 = least important)\n",
        "Grades: 1, 2, 3, 4\n",
        "Sports: 1, 2, 3, 4\n",
        "Looks: 1, 2, 3, 4\n",
        "Money: 1, 2, 3, 4\n",
        "```\n",
        "**There are many ways to read in Excel files, but the pandas library we used when we looked at the Indego bike data is one of the easiest.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "bXCqMH-jVRdJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the file into a pandas dataframe\n",
        "kids = pd.read_excel('PopularKids.xls')\n",
        "\n",
        "# Print the first ten rows\n",
        "kids.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "1LmxCo7PVRdK"
      },
      "outputs": [],
      "source": [
        "# How many rows and columns?\n",
        "kids.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbdBCra5VRdK"
      },
      "source": [
        "So the shape() function told us this data set has 478 rows and 11 columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "AmeYTDJ3VRdK"
      },
      "outputs": [],
      "source": [
        "# Let's see which factors the kids thought were most important (1 = most, 4 = least)\n",
        "kids.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYrBuTFCVRdK"
      },
      "source": [
        "The describe() function applied to a pandas dataframe returns summary statistics for all of the columns. Very slick!\n",
        "\n",
        "Looking at the averages (mean), the kids ranked them from most important to least important as: sports, looks, grades and money. I wonder what the results would be for college students?\n",
        "\n",
        "Well, I can't resist playing with the data a little.  Let's see how their opinions change with age from 7 to 13."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "DOn6FbwAVRdK"
      },
      "outputs": [],
      "source": [
        "# Group the data frame by ages\n",
        "by_age = kids.groupby('Age')\n",
        "\n",
        "# Find the averages for each age group\n",
        "# agg is short for \"aggregate\", in this case by mean value\n",
        "averages = by_age.agg(np.mean)\n",
        "\n",
        "# Display the averages for the columns of interest\n",
        "averages[['Grades', 'Sports','Looks', 'Money']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ZzBZcMNzVRdK"
      },
      "outputs": [],
      "source": [
        "# How many kids in each age group?\n",
        "print(by_age.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1LF2Aw3VRdL"
      },
      "source": [
        "There was only one 7-year-old, so the numbers for age 7 are just that kid's selection.  There were no 8 year olds in the data set, so that row is missing. I don't know why, so don't ask.\n",
        "\n",
        "Isn't it interesting, and perhaps a bit sad, that the one seven year old thought grades where most important, but with age, looks and athletic ability quickly become the most important factors? Well, maybe that kid's not typical. We really should limit comparison to ages where we have a lot of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "E8ym2P34VRdL"
      },
      "outputs": [],
      "source": [
        "# Look at just the nine year olds\n",
        "age9 = by_age.get_group(9)\n",
        "age9.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "LEwBgXLoVRdL"
      },
      "outputs": [],
      "source": [
        "# Look at the importance this group assigns to grades\n",
        "age9['Grades'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGzDykBWVRdL"
      },
      "source": [
        "### Student Challenge\n",
        "Create a similar histogram for the 11 year olds and comment on any changes you see between the 9 and 11 year olds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "w8tNs1ZTVRdL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj9_JVKrVRdL"
      },
      "source": [
        "### Students: add your interpretation here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiNPwDblVRdL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrF1060AVRdL"
      },
      "source": [
        "<a id='Googlesheet'></a>\n",
        "## Loading data from a Google Spreadsheet\n",
        "[Top of Notebook](#Top)\n",
        "\n",
        "The ability to load data from a Google spreadsheet is exciting because you can share Google spreadsheets with others to create a collaborative document. If you email the link to a bunch of friends, each can enter their own data, and you can use Python to compile the results automatically.\n",
        "\n",
        "For example, in my Geneneral Education class, \"Disasters, Geology vs. Hollywood,\" I challenge students to guess where on the Earth the biggest earthquake will occur each week. They enter three place names along with the latitude and longitude. Each week I download and plot their picks automatically and determine a winner by calculating who is closest to the actual biggest earthquake of the past 7 days. Doing this by hand would take considerable effort, but it only takes me a minute to run my Python script.  [Automating boring stuff](https://automatetheboringstuff.com/) is one of the advantages of learning to program.\n",
        "\n",
        "### Class Height\n",
        "To get an idea of how this works, I've created a Google Spreadsheet for you to enter your name and your height in inches. I've already entered my data, and so has one of my graduate students. Here is the spreadsheet link.\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1IvuiznSgfpGb7YTrizOBQKZ3FneqNeegV4wq1giJ1gA/edit?usp=sharing\n",
        "\n",
        "### Student Challenge\n",
        "*** Go to this spreadsheet and add your own information. Just open another tab on your browser. ***\n",
        "\n",
        "Now let's access these data from Python.  Because this spreadsheat is \"public\" this is not hard to do. Private spreadsheets require password or token-based authentification, which is a bit trickier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dSoe_ylVRdL"
      },
      "source": [
        "The spreadsheet above's link is a long string of characters, but notice at the end of the URL is: /edit?usp=sharing\n",
        "telling us that this a link for a shared sheet and that it is editable. This part at the end is a 'request' that is added to the URL (web address, or technically, the Universal Resource Locator). When you do an ordinary google search for any word you'll see your search terms added to the URL as a request (Try it in another browser tab). For example, when I search for \"python\" in a Google spreadsheet, the following URL is generated when I hit enter:\n",
        "https://www.google.com/search?q=python&oq=python&aqs=chrome..69i57j69i60l3j69i65j69i59.5701j0j4&sourceid=chrome&ie=UTF-8\n",
        "\n",
        "We actually want the Googlesheet request to return a CSV file (comma separated variable file) with the data when the URL is sent, so we have to modify the URL slightly. You'll see that in the code below.\n",
        "\n",
        "We use the Python module \"requests\" to send the web requests and the module \"StingIO\" (IO stands for input/output) to decode the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "VqjBp5w3VRdL"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# requests sends the string to the web server and provides an object to access the returned data\n",
        "# Notice the format=csv at the end of the URL string.\n",
        "\n",
        "sheet_url = 'https://docs.google.com/spreadsheets/d/1IvuiznSgfpGb7YTrizOBQKZ3FneqNeegV4wq1giJ1gA/export?format=csv'\n",
        "r = requests.get(sheet_url)\n",
        "\n",
        "# Need to use decode as .content returns bytes. UTF-8 (https://en.wikipedia.org/wiki/UTF-8) is a way\n",
        "# to encode characters that can handle all sorts\n",
        "# of symbols such as arabic and chinese characters.\n",
        "# At this point 'data' holds the contents of the CSV file in a big ol' string variable.\n",
        "\n",
        "data = r.content.decode('utf-8')\n",
        "\n",
        "# Now use pandas to read the CSV data from the string into a dataframe\n",
        "# Notice that we use SringIO to read from string variable instead of opening a file.\n",
        "\n",
        "df = pd.read_csv(StringIO(data))\n",
        "\n",
        "# Display the dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSNvxPj5VRdM"
      },
      "source": [
        "As other students add data to the Googlesheet the result of running this cell will update each time you run it.\n",
        "This is pretty cool!\n",
        "\n",
        "Note, this technique works only for a public spreadsheet. If you want Python to access a private spreadsheet the method is slightly more complicated because you have to pass authentification information in a way that doesn't make your password visible within your code.\n",
        "\n",
        "***The trick where you add something to the end of your URL to form a request, query, etc. is a way to communicate with web servers that offer a RESTful API.  What is a RESTful API? I'm glad you asked!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Vkip0SVRdM"
      },
      "source": [
        "## RESTful API\n",
        "\n",
        "Posted by: Margaret Rouse\n",
        "WhatIs.com\n",
        "\n",
        "> A RESTful API is an application program interface (API) that uses HTTP requests to GET, PUT, POST and DELETE data.\n",
        "\n",
        "> Representational state transfer (REST), which is used by browsers, can be thought of as the language of the Internet. Now that cloud usage is on the rise, various application programming interfaces (APIs) are emerging to expose Web services and REST is a logical choice for building APIs that allow end users to connect and interact with cloud services. RESTful APIs are used by many sites, including Google, Amazon, Twitter and LinkedIn.\n",
        "\n",
        "You'll get another chance to use a RESTful API in the Martian Challenge at the end of this notebook.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKvVQTCxVRdM"
      },
      "source": [
        "<a id='JSON'></a>\n",
        "## Loading data from a JSON file\n",
        "[Top of Notebook](#Top)\n",
        "\n",
        "The most common programming language of the web is Javascript. Storing data in [Java Script Object Notation](https://en.wikipedia.org/wiki/JSON) (JSON) format is very common. Not to worry, you don't have to learn Javascript (Which all right-thinking programmers agree is yucky). Python can read JSON files because, no surprise, someone has written a module for it. Actually, the JSON file format is very similar to a Python dictionary, so you almost don't need this module.\n",
        "\n",
        "Data is often served up by an Application Programmer's Interface (API). Meaning you send a query and data is returned as you desired. Just as in the example above, the query is stuff added to the URL. For this example we are going to ask for information from the [Open Movie Database](http://www.omdbapi.com/). Their website is cool because they show you how to construct the query string. To get information about the plot of, what else, \"The Martian\" (if by some tragic twist of fate you didn't see the movie), the query we need is: http://www.omdbapi.com/?t=The+Martian&y=&plot=short&r=json\n",
        "\n",
        "Notice the bits added to the end of the URL? There is t= for title, plot= for, well duh, plot, and r= for the format of the returned data, which you can see is json.\n",
        "\n",
        "To use this API, I had to request a free API-key.  This involves registering an email address. The free key is limited to 1,000 requests per day. I you want more than that you have to become a patron.  I think 1,000 is enough for me.\n",
        "\n",
        "Here is my key: OMDb API: http://www.omdbapi.com/?i=tt3896198&apikey=dcf0eedc\n",
        "You have to add the key to the end of the request to authenticate.\n",
        "\n",
        "Let's see how to perform this query from Python and display the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "l8pZuQdvVRdM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Notice that the request below asks for a short version of the plot\n",
        "url = 'http://www.omdbapi.com/?t=The+Martian&y=&plot=short&r=json'\n",
        "url_plus_key = url + \"OMDb API: http://www.omdbapi.com/?i=tt3896198&apikey=dcf0eedc\"\n",
        "\n",
        "# Make the request\n",
        "r = requests.get(url_plus_key)\n",
        "\n",
        "# Convert from bytes to unicode string\n",
        "data = r.content.decode('utf-8')\n",
        "\n",
        "# Load the data from the json string into a Python dictionary\n",
        "martian = json.loads(data)\n",
        "\n",
        "# Print the whole dictionary so you can see all the key:value pairs.\n",
        "print(martian)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpJe8_tPVRdM"
      },
      "source": [
        "The result is a dictionary. We can print any element in the usual way by passing using the dictionary key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "GRRe7ikGVRdM"
      },
      "outputs": [],
      "source": [
        "print(martian.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ponZIqccVRdM"
      },
      "outputs": [],
      "source": [
        "# Try one of the keys. Print the plot summary.\n",
        "print(martian['Plot'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMCldLUsVRdM"
      },
      "source": [
        "### Student Challenge\n",
        "See if you can retrieve the plot for a different movie of your choosing. You can either use my API key or register and obtain you own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xvamPaNVRdM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5nRGoFpVRdM"
      },
      "source": [
        "<a id='JSON'></a>\n",
        "## Scraping a Web Page\n",
        "[Top of Notebook](#Top)\n",
        "\n",
        "Many web pages display data in the form of a table, but do not provide any type of API, RESTful or unRESTful. Sure, you could cut and paste from the web page to get your data, but if the web page changes frequently cutting and pasting could get real old, real fast.\n",
        "\n",
        "The answer is to write a \"web scraper,\" which is a program that pulls the data directly from the web page. The most popular Python module written to scrape the web is called [beautiful soup](http://www.pythonforbeginners.com/beautifulsoup/beautifulsoup-4-python), a reference to Lewis Carroll and the Mock Turtle.  Since the beautiful soup module is designed to work directly with web pages, it helps to know something about HTML and XML, the formating language of the web. Don't worry, you only need to know a little.\n",
        "\n",
        "If you're just after tables, however, the pandas module can generally do the trick. First we use the urllib module to read the raw HTML from the target webpage.\n",
        "\n",
        "For this example we'll be looking at the latest golf player rankings. Not that I care about golf, but this is an example of a table on a webpage that changes regularly.  **Take a look at the website to see that table we're trying to scrape:** http://www.owgr.com/ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "c6xpZCHSVRdM"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Read the webpage\n",
        "r = requests.get('https://pythonprogramming.net/parsememcparseface/').text\n",
        "\n",
        "# Parse it into components (title, tables, etc., with the Python module lxml )\n",
        "soup = BeautifulSoup(r, \"html.parser\")\n",
        "print(type(soup))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ad27KrVHVRdN"
      },
      "outputs": [],
      "source": [
        "# Print the first 1000 characters in the web page to give you an idea what it looks like\n",
        "print(soup.prettify()[0:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPbaS1DgVRdN"
      },
      "source": [
        "All that stuff between angle brackets? That is HTML (Hypertext Markup Language).  So, for example, the title of the web page appears between < title \\> and < /title \\>.  The part we are looking for is the table, which appears a little further down with the key word < table >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4AH85UVYVRdN"
      },
      "outputs": [],
      "source": [
        "table = soup.find('table')\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz9uUDboVRdN"
      },
      "source": [
        "** Wow! That's a lot of table!**\n",
        "\n",
        "This has all the information, including table headers < th >, table rows < tr > and the table data < td >. But we need to parse the html to get the table data.  Every table entry is enclosed between the table data tags.  For example:\n",
        "< td >430.62< /td > is the table entry 430.62.\n",
        "\n",
        "We need to extract these values. We could write loops to do this, but here is where the pandas module can save us a lot of work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "kYeV_zK1VRdN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extact all of the tables from the HTML data into a list of data frames.\n",
        "table = pd.read_html(r)\n",
        "\n",
        "# There is only one table, so copy it into an appropriately named dataframe.\n",
        "golf_ranking = table[0]\n",
        "golf_ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_rCUZ9QVRdN"
      },
      "source": [
        "This is just a practice table. The approach I've used here will work for some tables but not others, especially ones there are generated live using datebases and javascript. Webscraping is whole world of programming techniques, with many applications, but I'm no expert so I'll stop here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwpqpyGjVRdN"
      },
      "source": [
        "### Import Point\n",
        "By webscraping the data one can update records automatically simply by re-running the script. Automating repetitive tasks is one of the key benefits of learning to program. Of course, writing and debugging programs takes time, so automation only pays when you need to do the same thing a lot of times.\n",
        "\n",
        "Often I ask myself, \"Is this something that would be faster to do editing by hand, or is it worth the time it takes to design, write and debug a program?\"\n",
        "\n",
        "This dilemma is so common there is an XKCD cartoon about it:\n",
        "\n",
        "![XKCD cartoon](https://imgs.xkcd.com/comics/automation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAnp1aPuVRdS"
      },
      "source": [
        "### Student Challenge\n",
        "This is just a writing exercise. Describe a website where you might be interested in scraping data on a regular basis. Include the URL. Maybe I'll look into it with you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCxxeJXPVRdS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo0SexOLVRdS"
      },
      "source": [
        "<a id='Mission'></a>\n",
        "## Martian Challenge: NASA APIs\n",
        "[Top of Notebook](#Top)\n",
        "\n",
        "Naturally, NASA offers quite a few APIs, which you can read about [here](https://api.nasa.gov/). Once again, I had to register to obtain an API key.\n",
        "\n",
        "You can start using this key to make web service requests. Simply pass your key in the URL when making a web request. Here's an example:\n",
        "\n",
        "https://api.nasa.gov/planetary/apod?api_key=fI1pDC6MTYNaEkCDosx4Yk1RcMZRGMvpiVBK4Bcb\n",
        "\n",
        "### Example\n",
        "** Look at the documentation on retrieving [Mars Rover Photos](https://api.nasa.gov/api.html#assets). ** In the example below, I retrieve and plot\n",
        "\n",
        "https://api.nasa.gov/api.html#MarsPhotos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6R_qBsfVRdS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Look at the end of the url. This request is for Sol day 10, Front hazard avoidance camera\n",
        "url = 'https://api.nasa.gov/mars-photos/api/v1/rovers/curiosity/photos?sol=1000&camera=fhaz&api_key=fI1pDC6MTYNaEkCDosx4Yk1RcMZRGMvpiVBK4Bcb'\n",
        "\n",
        "# Make the request\n",
        "r = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "mIJ1pGsbVRdS"
      },
      "outputs": [],
      "source": [
        "# Convert from bytes to unicode string\n",
        "data = r.content.decode('utf-8')\n",
        "\n",
        "# Read the json data\n",
        "rover_metadata = json.loads(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "RrBMcoY-VRdS"
      },
      "outputs": [],
      "source": [
        "# Print the dictionary of information returned by the query\n",
        "# Notice that this is a complicated nested structure of lists and dictionaries inside a dictionary\n",
        "rover_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh6EfS7qVRdS"
      },
      "source": [
        "The information we need is the img_src (image source), which provides the url for the image we wanted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Xj5V7qsnVRdS"
      },
      "outputs": [],
      "source": [
        "# Look carfully at the output of the previous cell and you'll see that\n",
        "# img_src is a key in a dictionary that is in the first list that is in the dictionary named 'photos'.\n",
        "# So we reference it this way:\n",
        "rover_metadata['photos'][0]['img_src']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "K1R-tDebVRdS"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = rover_metadata['photos'][0]['img_src']\n",
        "\n",
        "# create a file-like object from the url\n",
        "f = urllib.request.urlopen(url)\n",
        "\n",
        "# read the image file in a numpy array\n",
        "a = plt.imread(f, format='jpg')\n",
        "\n",
        "# Plot the image using a greyscale (black and white) colormap\n",
        "plt.imshow(a,  cmap='Greys_r')\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6MYkxpjVRdT"
      },
      "source": [
        "### Student Challenge: Your Mission\n",
        "See if you can retrieve and plot an image from one of the other cameras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCDdews4VRdT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj3faY_RVRdT"
      },
      "source": [
        "# Supplemental Activity\n",
        "I assume you all have Google accounts.  Create your own Google spreadsheet with simple columns and headers. Make the sheet public and editable by anyone with the link, then see if you can write the python code to load the data into a Pandas dataframe and print it. Extras kudos if you plot the data too!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoIsIxHKVRdT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}